{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2348f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.12\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3399f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\spark'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70183c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf07f070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf, col\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator, CrossValidatorModel\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5911c667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "mydb = myclient[\"mydatabase\"]\n",
    "mycol = mydb[\"customers\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a0835b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict = { \"text\":\"se référant à l'ensemble des altérations de\",\"method\":200 }\n",
    "\n",
    "x = mycol.insert_one(mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6b399ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>link line</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sport jeux</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clée usb</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>La maladie est une altération</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>se référant à l'ensemble des altérations de</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text  method\n",
       "0                                    link line     404\n",
       "1                                   sport jeux     200\n",
       "2                                     clée usb     300\n",
       "3                La maladie est une altération     200\n",
       "4  se référant à l'ensemble des altérations de     200"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "x = mycol.find()\n",
    "l=[]\n",
    "\n",
    "for data in x:\n",
    "    new_list = list(data.values())\n",
    "    new_list.pop(0)\n",
    "    \n",
    "    l.append(new_list)\n",
    "    \n",
    "df1=pd.DataFrame(l ,columns=[\"text\",\"method\"])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d239c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession(sc).builder.appName(\"TP_ML_Email_spam\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4ae32db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[2]\").appName(\"Linear-Regression-California-Housing\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b4033cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the schema, corresponding to a line in the csv data file.\n",
    "schema = StructType([\n",
    "    StructField(\"text\", StringType(), nullable=True),\n",
    "    StructField(\"class\", IntegerType(), nullable=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "23a043e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame (df1, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4d97f91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|class|\n",
      "+--------------------+-----+\n",
      "|           link line|  404|\n",
      "|          sport jeux|  200|\n",
      "|            clée usb|  300|\n",
      "|La maladie est un...|  200|\n",
      "|se référant à l'e...|  200|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "156d437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter((df['class']==\"404\")|(df['class']==\"200\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b12e4156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|class|\n",
      "+--------------------+-----+\n",
      "|           link line|  404|\n",
      "|          sport jeux|  200|\n",
      "|La maladie est un...|  200|\n",
      "|se référant à l'e...|  200|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6beab9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f7830681",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a5365d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"\\\\W\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3de91df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "regexTokenized = regexTokenizer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "92d93850",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = tokenizer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6b646d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|                text|class|               words|\n",
      "+--------------------+-----+--------------------+\n",
      "|           link line|  404|        [link, line]|\n",
      "|          sport jeux|  200|       [sport, jeux]|\n",
      "|La maladie est un...|  200|[la, maladie, est...|\n",
      "|se référant à l'e...|  200|[se, référant, à,...|\n",
      "+--------------------+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "13559256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e7ccbd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f7911062",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = remover.transform(regexTokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d6465aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+\n",
      "|                text|class|               words|            filtered|\n",
      "+--------------------+-----+--------------------+--------------------+\n",
      "|           link line|  404|        [link, line]|        [link, line]|\n",
      "|          sport jeux|  200|       [sport, jeux]|       [sport, jeux]|\n",
      "|La maladie est un...|  200|[la, maladie, est...|[la, maladie, est...|\n",
      "|se référant à l'e...|  200|[se, r, f, rant, ...|[se, r, f, rant, ...|\n",
      "+--------------------+-----+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "edb0ca84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(words=['link', 'line'])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select('words').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "45595fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(filtered=['link', 'line'])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select('filtered').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "be39a208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mots(txt):\n",
    "    return [w for w in txt if ((len(w) > 2) & (w != 'subject'))  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3c7e455d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sam', 'fat']\n"
     ]
    }
   ],
   "source": [
    "str = [\"subject\",\"sam\",\"de\",\"fat\",\"*\",\"--\"]\n",
    "print(mots(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d67b698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "mots = udf(mots,ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d633ea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "toNum = lambda str:int(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "375ddd8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toNum('3')+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "56026d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "toNum = udf(toNum,'int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "744e2395",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.withColumn('motsPur', mots(data[\"filtered\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8a673393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-------------+-------------+-------------+\n",
      "|      text|class|        words|     filtered|      motsPur|\n",
      "+----------+-----+-------------+-------------+-------------+\n",
      "| link line|  404| [link, line]| [link, line]| [link, line]|\n",
      "|sport jeux|  200|[sport, jeux]|[sport, jeux]|[sport, jeux]|\n",
      "+----------+-----+-------------+-------------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "22fb85e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data2.withColumn('label', toNum(data[\"class\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "edb84ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-------------+-------------+-------------+-----+\n",
      "|      text|class|        words|     filtered|      motsPur|label|\n",
      "+----------+-----+-------------+-------------+-------------+-----+\n",
      "| link line|  404| [link, line]| [link, line]| [link, line]|  404|\n",
      "|sport jeux|  200|[sport, jeux]|[sport, jeux]|[sport, jeux]|  200|\n",
      "+----------+-----+-------------+-------------+-------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9213fecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(motsPur=['link', 'line'])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.select('motsPur').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "223a1c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|label|\n",
      "+-----+\n",
      "|  404|\n",
      "|  200|\n",
      "|  200|\n",
      "|  200|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2.select('label').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9b087ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "84f8478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a CountVectorizerModel from the corpus.\n",
    "cv = CountVectorizer(inputCol=\"motsPur\", outputCol=\"features\")\n",
    "data3 = cv.fit(data2).transform(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "eb696bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data3.select('features','label').randomSplit([0.5,0.5],seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a117ebe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(13,[4,6],[1.0,1.0])|  200|\n",
      "|(13,[0,5,8,11,12]...|  200|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "85275e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(13,[2,3],[1.0,1.0])|  404|\n",
      "|(13,[0,1,7,9,10],...|  200|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9cdd05d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5d62fd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the trainer and set its parameters\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "# train the model\n",
    "model = nb.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "68bf3c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select example rows to display.\n",
    "predictions = model.transform(test)\n",
    "#predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7b3239cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select example rows to display.\n",
    "test2 = test.select('features')\n",
    "predictions2 = model.transform(test2)\n",
    "#predictions2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c930654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1cf6acda",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cdd33808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5a3406e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
